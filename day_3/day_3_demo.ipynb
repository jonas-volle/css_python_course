{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f730a8",
   "metadata": {},
   "source": [
    "# Einführung in Python für die Computational Social Science (CSS)\n",
    "\n",
    "## Jonas Volle\n",
    "Wissenschaftlicher Mitarbeiter  \n",
    "Chair of Methodology and Empirical Social Research  \n",
    "Otto-von-Guericke-Universität\n",
    "\n",
    "[jonas.volle@ovgu.de](mailto:jonas.volle@ovgu.de)\n",
    "\n",
    "**Sprechstunde**: individuell nach vorheriger Anmeldung per [Mail](mailto:jonas.volle@ovgu.de)\n",
    "\n",
    "Freitag, 07.07.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e01ee4",
   "metadata": {},
   "source": [
    "**Quelle:** Ich orientiere mich für diese Sitzung teils an den Kapiteln 4 und 5 aus dem Buch:  \n",
    "\n",
    "McLevey, John. 2021. Doing Computational Social Science: A Practical Introduction. 1st ed. Thousand Oaks: SAGE Publications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278555f",
   "metadata": {},
   "source": [
    "# Tag 3: APIs und Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6877dff4",
   "metadata": {},
   "source": [
    "## Inhalt\n",
    "\n",
    "- API\n",
    "- Webscraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d687809",
   "metadata": {},
   "source": [
    "## Application Programming Interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a3725",
   "metadata": {},
   "source": [
    "### Was ist ein API?\n",
    "\n",
    "- **I**nterface (Benutzeroberfläche): Interaktion zwischen Mensch und Computer, um bestimmte Aufgaben zu erledigen, ohne dass er verstehen muss, wie diese Aufgabe tatsächlich ausgeführt wird.  \n",
    "- Wie Benutzeroberflächen machen APIs schwierige Dinge einfacher, indem sie eine Menge von Prozessen auf niedriger Ebene abstrahieren. APIs bündeln Funktionen damit diese besonders leicht zu verstehen und zu verwenden sind.\n",
    "\n",
    "### RESTful APIs\n",
    "- Besondere Art von APIs, die auf dem REST (Representational State Transfer) Prinzip basieren.\n",
    "- RESTful APIs ermöglichen die Kommunikation und den Datenaustausch zwischen verschiedenen Anwendungen über das Internet.\n",
    "- RESTful APIs arbeiten nach dem Client-Server-Modell, wobei der Client Anfragen (Requests) an den Server sendet und der Server entsprechend antwortet.\n",
    "- Die Daten werden normalerweise im JSON- oder XML-Format übertragen.\n",
    "- RESTful APIs sind zustandslos, was bedeutet, dass jede Anfrage unabhängig ist und der Server keine Informationen über vergangene Anfragen speichert.\n",
    "- Zugriff über Endpunkte (Endpoints)\n",
    "\n",
    "### Requests mit Python\n",
    "- Requests werden an einen bestimmten Endpunkt (Endpoint) gesendet in Form einer URL (APIs können verschiedene Enpoints haben!)\n",
    "- Diese URL besteht aus verschiedenen Teilen, die wir so spezifizieren können (Suchbegriffe, Filter, Parameter etc.), sodass wir den gewünschten Inhalt zurück bekommen.\n",
    "- Die meisten APIs haben *rate limits*, also Obergrenzen für Anfragen in einer bestimmten Zeitspanne. \n",
    "\n",
    "### API keys oder tokens\n",
    "- Um Anfragen an einen API zu senden, benötigen wir in den meisten Fällen einen API key oder API token.\n",
    "- API keys oder tokens funktionieren wie Benutzername und Passwort die uns identifizieren.\n",
    "- Diese keys können auf der jeweiligen Webseite des APIs beantragt werden und werden uns dann zugewiesen.\n",
    "- Es ist wichtig, dass wir diese Zugangsdaten nicht teilen, das heißt auch nicht direkt in unser Script schreiben.\n",
    "\n",
    "### Responses\n",
    "- Wenn wir eine GET-Anfrage an den API senden, bekommen wir im Gegenzug eine Antwort (response)\n",
    "- In den meisten Fällen bekommen wir die Daten im `json`-Format zurück. Das steht für *JavaScript Object Notation*.\n",
    "- `json` ist eine genestete Datenstruktur, die aussieht wie ein *dictionary* in Python und in der die Daten in *key-value* Paaren gespeichert sind.\n",
    "- Mit dem Python Paket `json` können wir diese Datenstrukturen wie ein `dictionary` behandeln.\n",
    "- Mit `pandas` Methode `.read_json()` können wir dieses Datenformat auch direkt in einen Dataframe umwandeln."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca053de",
   "metadata": {},
   "source": [
    "## The Guardian API\n",
    "\n",
    "Die Zeitung 'The Guardian' bietet fünf verschiedene Endpunkte:\n",
    "\n",
    "1. Der content-Endpoint liefert den Text und die Metadaten für veröffentlichte Artikel. Es ist möglich, die Ergebnisse mittels Suchanfragen abzufragen und zu filtern. Dieser Endpunkt ist wahrscheinlich der nützlichste für Forscher. \n",
    "2. Der tags-Endpunkt liefert API-Tags für mehr als 50.000 Ergebnisse, die in anderen API-Abfragen verwendet werden können. \n",
    "3. Der sections-ENdpunkt liefert Informationen über die Gruppierung veröffentlichter Artikel in Sektionen. \n",
    "4. Der editions-Endpunkt liefert Inhalte für jede der regionalen Hauptseiten: USA UK, Australien und International. \n",
    "5. Der single-Endpunkt Punkt liefert Daten für einzelne Elemente, einschließlich Inhalt, Tags und Abschnitte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f968dc",
   "metadata": {},
   "source": [
    "In vielen Fällen gibt es in Python schon Clients für einschlägige APIs. Diese Clients sind Pakete und beinhalten eine Reihe an Funktionen, die die Arbeit mit dem API erleichtert. In diesem Fall arbeiten wir aber mit dem `requests` Paket direkt mit dem API um die Logik hinter den API-Anfragen und Antworten zu verstehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505710f6",
   "metadata": {},
   "source": [
    "### Zugriff auf den Guardian API\n",
    "\n",
    "Zunächst müssen wir uns für einen API-key registrieren. Das geht hier: https://bonobo.capi.gutools.co.uk/register/developer\n",
    "\n",
    "Nach der erfolgreichen Registrierung bekommen wir einen key zugesendet, den wir speichern müssen. Dafür erstellen wir eine Datei mit dem Namen `cred.py` im gleichen Ordner wie dieses Notebook. In dieser Datei weisen wir der Variable `GUARDIAN_KEY` den zugesendeten Key zu. Wenn wir git zur Versionskontrolle nutzen, können wir diese Datei der `.gitignore` Liste hinzufügen. Dann wird unser Key nicht synchronisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9173c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "GUARDIAN_KEY = 'paste_your_key_here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ab1c5",
   "metadata": {},
   "source": [
    "Diese Datei können wir dann in unser Script importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4da56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e585ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0069f991",
   "metadata": {},
   "source": [
    "Wir verwenden ein Paket namens `requests`, um unsere API-Anfragen zu stellen. Sobald das Paket importiert wurde, können wir dies tun, indem wir die Methode `.get()` mit der Basis-API-URL für den Inhaltsendpunkt versehen. Außerdem erstellen wir ein Wörterbuch namens `PARAMS`, das ein Key-Values-Paar für unseren API-Schlüssel enthält. Später werden wir diesem Wörterbuch weitere Key-Values-Paare hinzufügen, um zu ändern, was die API zurückgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9b32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Endpoint\n",
    "API_ENDPOINT = 'http://content.guardianapis.com/search' \n",
    "\n",
    "# API Parameter\n",
    "PARAMS = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET request\n",
    "\n",
    "\n",
    "# json Datei als dictionary speichern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsere Anfrage besteht aus dieser URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245c6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was sind die keys des dictionaries?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce81a7b2",
   "metadata": {},
   "source": [
    "Die Ergebnisse sind dem key `'results'` zugewiesen. Results besteht aus einem dictionary je Eintrag. Diese dictonaries befinden sich in einer Liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc8440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f3c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff299f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e39e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e0cc7e4",
   "metadata": {},
   "source": [
    "### Ergebnisse filtern\n",
    "Wir können unserer API Anfrage noch weitere Parameter hinzufügen. Diese Parameter können wir der Dokumentation entnehmen: https://open-platform.theguardian.com/documentation/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9dc537",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = { \n",
    "    'api-key': GUARDIAN_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf07ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abb31484",
   "metadata": {},
   "source": [
    "Unsere Anfrage besteht aus dieser URL. Die Antwort können wir uns auch im Browser anschauen. Hierbei bietet sich eine json Erweiterung an, die das Ergebnis schön formatiert. Für Chrome z.B. JSONVue (https://chrome.google.com/webstore/detail/jsonvue/chklaanhfefbnpoihckbnefhakgolnmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59007791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsere Anfrage besteht aus dieser URL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488209ff",
   "metadata": {},
   "source": [
    "Damit wir auch die Texte der Artikel mit ausgegeben bekommen, müssen wir unsere Parameter ändern und Felder hinzufügen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'api-key': GUARDIAN_KEY\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492e680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156d360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e92e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a31ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903028ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29829bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea55cc29",
   "metadata": {},
   "source": [
    "### Größere Anfragen senden\n",
    "\n",
    "Bis jetzt haben wir nur Daten für 10 Artikel erhalten. Wenn wir mehr Artikel bekommen wollen, müssen wir ein weiteres Konzept von APIs verstehen:  \n",
    "Jede Antwort enhält neben den results auch Metadaten:\n",
    "- `response_dict['total']` --> Anzahl der Artikel\n",
    "- `response_dict['pages']` --> Anzahl der Seiten\n",
    "- `response_dict['pageSize']` --> Anzahl der Artikel je Seite\n",
    "- `response_dict['currentPage']` --> Aktuelle Seite\n",
    "\n",
    "APIs funktionieren wie Suchmaschinen, sie geben die Ergebnisse auf verschiedenen Seiten zurück. Wir können die oben genannten Parameter mit in unsere API-Anfrage aufnehmen, um etwa auf eine bestimmte Seite zu navigieren, oder die Größe der jeweiligen Seiten zu bestimmen. Wenn wir alle Ergebnisse haben möchten, müssen wir mit einem Loop über alle Seiten loopen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffaf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cc703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961cada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31477a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007d1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "710d4c1e",
   "metadata": {},
   "source": [
    "Wir vergrößern die Anzahl der Artikel je Seite, indem wir den Parameter `page-size` erhöhen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00531d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'api-key': GUARDIAN_KEY\n",
    "} \n",
    "\n",
    "response = requests.get(API_ENDPOINT, params=PARAMS) \n",
    "response_dict = response.json()['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19275bc5",
   "metadata": {},
   "source": [
    "Mit einem `while`-Loop können wir uns jede Seite des Ergbisses anzeigen lassen. Die Ergebnisse jeder Seite speichern wir in der List `all_results`. Damit wir nicht über die `rate-limits` des APIs kommen, können wir `time.sleep()` benutzen um, in jeder Runde ein bisschen zu warten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49252f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb9f7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d485e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72396eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "044446fe",
   "metadata": {},
   "source": [
    "### Ergebnisse speichern\n",
    "\n",
    "Nun sollten wir unsere Daten auf unserer Festplatte speichern, um später auf sie zurückgreifen zu können, ohne den API überflüssig benutzen zu müssen. Es bietet sich auch an den Code für die Datenerhebung und Analyse zu trennen.  \n",
    "\n",
    "Wir können unsere Daten mit dem `json` Modul auf unsere Festplatte schreiben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "FILE_PATH = '../data/guardian_api_results.json'\n",
    "\n",
    "with open(FILE_PATH, 'w') as outfile:\n",
    "    json.dump(all_results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fbcf51",
   "metadata": {},
   "source": [
    "So können wir die Daten dann wieder lesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '../data/guardian_api_results.json'\n",
    "\n",
    "with open(FILE_PATH) as f:\n",
    "    guardian_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c232c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0560bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbe10210",
   "metadata": {},
   "source": [
    "### Ergebnisse in einem DataFrame speichern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaab748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ebb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48260a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "858eb052",
   "metadata": {},
   "source": [
    "Mit dem Paket `BeautifulSoup` können wir aus dem html-body den reinen Text extrahieren. Das `beautifulSoup` Paket lernen wir im nächsten Abschnitt zum Webscraping geanuer kennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13328c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab31d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61753327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916953bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "677384c8",
   "metadata": {},
   "source": [
    "Die Date Variabel können wir in eine Pandas Datumsvariable verwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e8a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82e86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5db89def",
   "metadata": {},
   "source": [
    "Wir können Spalten umbenennen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b68f0",
   "metadata": {},
   "source": [
    "... und eine Auswahl an Spalten als csv Datei speichern. Diese csv Datei können wir dann später wieder in einen Pandas DataFrame laden und analysieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95ff70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ada86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0af595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9892b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91720920",
   "metadata": {},
   "source": [
    "## Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac35f85",
   "metadata": {},
   "source": [
    "- Twitter bietet einen kostenlosen Zugang auf 1.500 Tweets im Monat an\n",
    "- Für den Zugang ist ein Twitter Account nötig und die Registrierung im Developer Portal\n",
    "- In Python gibt es verschiedene Pakete, die den API-Zugang erleichtern: `Tweepy` und `twarc`\n",
    "- Sie finden bspw. hier ein Tutorial für `twarc`: https://melaniewalsh.github.io/Intro-Cultural-Analytics/04-Data-Collection/11-Twitter-API-Setup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a9bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1d802ce",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d384ac1",
   "metadata": {},
   "source": [
    "- Webscraping Techniken benutzen wir, wenn wir keinen direkten Zugriff auf die Daten einer Webseite z.B. durch eine API haben\n",
    "- Für Webscraping benötigen wir Grundkenntnisse in HTML und CSS\n",
    "- Mit Webscraping Techniken ist es möglich von quasi jeder Webseite Daten zu extrahieren\n",
    "- Beim Scrapen sollte sich aber immer an Ethische Standards gehalten werden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "<html> \n",
    "    <head> \n",
    "    <title>This is a minimal example</title> \n",
    "    </head> \n",
    "    <body> \n",
    "        <h1>This is a first-level heading</h1> \n",
    "        <p>A paragraph with some <emph>italicized</emph> text. </p> \n",
    "        <p lang=\"en-us\">American English sentence here...</p>\n",
    "        <img src=\"image.pdf\" alt=\"\"> <p>A paragraph with some <strong>bold</strong> text. </p>\n",
    "        <h2>This is a second-level heading</h2> \n",
    "        <ul> \n",
    "            <li>first list item</li> \n",
    "            <li>second list item</li> \n",
    "        </ul> \n",
    "    </body> \n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dfbf9",
   "metadata": {},
   "source": [
    "### div\n",
    "Das Divisions-Tag div ist ein allgemeiner Container, der eine Website in kleinere Abschnitte unterteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68987a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "<div>\n",
    "\n",
    "</div>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24334872",
   "metadata": {},
   "source": [
    "### css\n",
    "- Die meisten Webseite trennen den Inhalt der Webseite von der Struktur und dem Style\n",
    "- HTML sagt dem Browser, was ein bestimmter Text ist (z. B. eine Überschrift, ein Listenelement, eine Zeile in einer Tabelle, ein Absatz)\n",
    "- CSS teilt dem Browser mit, wie der Text aussehen soll, wenn er im Browser gerendert wird (z. B. welche Schriftart für Zwischenüberschriften zu verwenden ist, wie groß der Text sein soll, welche Farbe der Text haben soll usw.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "<div id='content' class='dcr1'>\n",
    "\n",
    "</div>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52fd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e2c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddcd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a4ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.theguardian.com/world/2020/apr/10/coronavirus-latest-at-a-glance-summary'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7837d74",
   "metadata": {},
   "source": [
    "Mit dem `requests` Paket stellen wir eine `GET` Anfrage an die Webseite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba405637",
   "metadata": {},
   "source": [
    "Mit der `BeautifulSoup` Funktion aus dem gleichnamigen Paket lesen wir das html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671c5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cdc360a",
   "metadata": {},
   "source": [
    "In unserem Browser können wir die Webseite *untersuchen* und nach den Elementen suchen, die wir extrahieren möchten. Mit den Funktionen `.findAll()` oder `.find()` können wir nach den Elementen suchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6ad28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a02cd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae02eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de65a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05178625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e61cbfd",
   "metadata": {},
   "source": [
    "Wir können uns eine Funktion bauen, um verschiedene Elemente auf der Webseite zu extrahieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7638ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae83795d",
   "metadata": {},
   "source": [
    "Diese Funktion können wir auf eine Liste an urls anwenden. Hier auf die Liste der guardian urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe8594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8c554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340e4691",
   "metadata": {},
   "source": [
    "Diese Liste aus Listen können wir ganz einfach in einen DataFrame umwandeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb7063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd3448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90a7809f",
   "metadata": {},
   "source": [
    "... und als csv Datei speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cac1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f0ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b482d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c696987e",
   "metadata": {},
   "source": [
    "### Elemente auswählen\n",
    "\n",
    "Jetzt möchten wir nicht immer nur Titel und Texte scrapen, sondern auch spezifische Felder auf einer Webseite. Mit Beautifulsoup können wir jedes html-Feld finden mit einem bestimmten Locator. Wir benutzen dafür die Funktion: `soup.find(\"html-container\", {\"class/id etc.\": \"class/id etc. name\"})` oder `soup.find_all()`  \n",
    "\n",
    "Beispielhaft schauen wir uns diese Webseite an: https://www.unimagazin.ovgu.de/Beitr%C3%A4ge/2022/Januar/F%C3%BCr+eine+starke+Gemeinschaft+brauchen+wir+vielf%C3%A4ltige+Talente.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.unimagazin.ovgu.de/Beitr%C3%A4ge/2022/Januar/F%C3%BCr+eine+starke+Gemeinschaft+brauchen+wir+vielf%C3%A4ltige+Talente.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc98ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get(url).content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a5480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titel des Beitrags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schlagwörter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b8ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b8282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba60427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029874bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6dccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec428b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457fb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db2a9b3",
   "metadata": {},
   "source": [
    "### Tabellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a577a",
   "metadata": {},
   "source": [
    "- Tabellen sind in einem `<table> </table>` Container gespeichert\n",
    "- Tabellen können Spaltennamen haben. Diese sind in `<thead> </thead>` gespeichert.\n",
    "- Der Inhalt der Tabelle befindet sich in `<tbody> </tbody>`\n",
    "- Zeilen befinden sich in `<tr> </tr>`\n",
    "- Spalten in `<th> </th>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61955055",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html ='''\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Überschrift 1</th>\n",
    "            <th>Überschrift 2</th>\n",
    "            <th>Überschrift 3</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "\n",
    "    <tbody>\n",
    "    <tr>\n",
    "      <td><p>R1 - S1</p></td>\n",
    "      <td><p>R1 - S2</p></td>\n",
    "      <td><p>R1 - S3</p></td>\n",
    "    </tr>\n",
    "    \n",
    "    <tr>\n",
    "      <td><p>R2 - S1</p></td>\n",
    "      <td><p>R2 - S2</p></td>\n",
    "      <td><p>R2 - S3</p></td>\n",
    "    </tr>\n",
    "    \n",
    "    <tr>\n",
    "      <td><p>R3 - S1</p></td>\n",
    "      <td><p>R3 - S2</p></td>\n",
    "      <td><p>R3 - S3</p></td>\n",
    "    </tr>\n",
    "\n",
    "    </tbody>\n",
    "\n",
    "</table>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36e34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf7ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f6a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a1abcb8",
   "metadata": {},
   "source": [
    "Manche Tabellen haben keine Überschrift im `thead`, sondern haben ihre `keys` in der ersten Spalte und die `values` in der zweiten Spalte. Das Datenformat ist dann ähnlich eines `dictionaries`. Genau so extrahieren wir die Informationen dann auch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd147e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html_2 ='''\n",
    "<table>\n",
    "    <tbody>\n",
    "    <tr>\n",
    "      <td><p>Name</p></td>\n",
    "      <td><p>Jonas</p></td>\n",
    "    </tr>\n",
    "    \n",
    "    <tr>\n",
    "      <td><p>Größe</p></td>\n",
    "      <td><p>190</p></td>\n",
    "    </tr>\n",
    "\n",
    "    </tbody>\n",
    "\n",
    "</table>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec7a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b33f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cc9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d7bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300310c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6670cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e060d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f23887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a03cc3f",
   "metadata": {},
   "source": [
    "**Beispiel**: Scopus Journal Classification Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63940281",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://service.elsevier.com/app/answers/detail/a_id/15181/supporthub/scopus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd3f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471827e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e98e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187a43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad1eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af47e892",
   "metadata": {},
   "source": [
    "**Zeit für Übung 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf9e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1ea3841",
   "metadata": {},
   "source": [
    "### Webscraping mehrerer Seiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f977ea3",
   "metadata": {},
   "source": [
    "Oft sind die Inhalte auf einer Webseite die wir extrahieren möchten auf unterschiedlichen Seiten gespeichert. Beispielhaft scrapen wir nun alle Artikel auf der Webseite: https://www.cyclingnews.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31c44d",
   "metadata": {},
   "source": [
    "Zunächst lesen wir das html ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.cyclingnews.com/news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab46d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get(url).content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de15eb5",
   "metadata": {},
   "source": [
    "Wir schauen uns nun als erstes die erste Seite an und erstellen eine Routine, die wir dann für jede Seite mittels eines Loops anwenden können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe453dc",
   "metadata": {},
   "source": [
    "Die Artikel sind in diesem Fall in einem `div` Container gespeichert. Mit der Funktion `.find_all()` finden wir alle `div` Container mit der gleichen Klasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115152e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553caee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f78124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ef96b45",
   "metadata": {},
   "source": [
    "Nun schauen wir uns den **ersten** div-Container an und entwickeln eine Routine, die wir dann auf alle Container anwenden können. Wir such in diesem Container nach den Informationen, die wir extrahieren möchten. Diese Elemente können wir in unserem Browser mit der 'untersuchen' Funktion lokalisieren und deren Indtifier in die `.find()` Funktion eintragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78607a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e87de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a12fc7",
   "metadata": {},
   "source": [
    "Alle gewünschten Informationen sammeln wir nun in einer Funktion, die wir dann auf alle div-Container loslassen können. Hier verwenden wir try/except Blöcke um mit möglichen Fehlern umgehen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78719bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb4e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6127a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22e888f8",
   "metadata": {},
   "source": [
    "Jetzt versuchen wir nicht nur eine Seite zu scrapen, sondern mehrere Seite mit Hilfe eines Loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffe5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste mit allen Seiten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b516df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad176102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1223ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop über jede Seite:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5215b",
   "metadata": {},
   "source": [
    "Da wir nun eine List von Listen von Listen haben, müssen wir diese Liste flacher machen, d.h. in eine Liste aus Listen verwandeln. Das geht mit diesem kleinen Code-Schnipsel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list\n",
    "all_results_flat = [i for s in all_results for i in s]\n",
    "all_results_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d017a9",
   "metadata": {},
   "source": [
    "Diese Liste aus Listen können wir nun in einen DataFrame umwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3935a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7baaa0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3b04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "139c987a",
   "metadata": {},
   "source": [
    "Nun haben wir eine Tabelle mit allen Artikeln auf der Webseite. Der Text ist aber noch nicht enthalten, da dieser auf einer eigenen Webseite ist. Wir haben aber alle urls dieser Unterwebseiten. Das heißt wir können mit einem Loop über alle Webseiten loopen und dort den entsprechenden Text extrahieren. hierzu schreiben wir zunächst eine Funktion, die wir dann auf alle webseiten anwenden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape text for every article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414e7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e35ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.cyclingnews.com/news/tour-de-france-femmes-to-start-in-rotterdam-in-2024/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab218866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "868a0436",
   "metadata": {},
   "source": [
    "Diese Funktion wenden wir nun auf alle urls an. Dafür benutzen wir einen for-Loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c272f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cc80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7820191d",
   "metadata": {},
   "source": [
    "Nun haben wir einen DataFrame mit den Metadaten (url, titel, author etc.) und einen DataFrame mit den jeweiligen Texten und der url. Beide DataFrames können wir nun anhand der url mergen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d96de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e4fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffab55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08684d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d18511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf41569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "972579a5",
   "metadata": {},
   "source": [
    "**Zeit für Übung 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45db720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f61dfc16",
   "metadata": {},
   "source": [
    "### Ethische und rechtliche Einschränkungen beim Webscrapen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdc36c",
   "metadata": {},
   "source": [
    "- Auch wenn es möglich ist jeden Part einer Webseite automatisiert zu extrahieren, heißt das NICHT, dass wir das auch dürfen!\n",
    "- Manche Webseiten verbieten webscraping in ihren Nutzungsbedingungen, und in einigen Fällen können diese Webseits rechtliche Schritte einleiten, wenn wir diese Daten irgendwo verwenden\n",
    "- Wir wollen auf jeden Fall vermeiden, dass uns beim Web Scraping rechtliche Schritte drohen\n",
    "- Bitte Prüfen Sie immer die Nutzungsbedingungen der Websites, die Sie scrapen.\n",
    "- Als allgemeine Regel gilt: Wenn Websites den Zugang zu Daten in großem Umfang ermöglichen wollen, werden sie eine API einrichten, um sie bereitzustellen\n",
    "- Wenn dies nicht der Fall ist, sollten Sie darauf verzichten, Daten in großem Umfang zu sammeln, und Ihre Datenerfassung auf das beschränken, was Sie benötigen, anstatt alle Daten zu sammeln und später zu filtern\n",
    "- Manche Websites verweigern den Dienst, wenn wir zu viele Anfragen stellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542743b0",
   "metadata": {},
   "source": [
    "Die am weitesten verbreitete Position in der Wissenschaft zu Webscraping scheint zu sein, dass öffentliche Online-Inhalte mit denselben Standards behandelt werden sollten, die man auch bei der Beobachtung von Menschen in öffentlichen Umgebungen anwenden würde, wie es z.B. Ethnographen tun (vgl. McLLevey 2021)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
