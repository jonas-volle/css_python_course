{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f730a8",
   "metadata": {},
   "source": [
    "# Einführung in Python für die Computational Social Science (CSS)\n",
    "\n",
    "## Jonas Volle\n",
    "Wissenschaftlicher Mitarbeiter  \n",
    "Chair of Methodology and Empirical Social Research  \n",
    "Otto-von-Guericke-Universität\n",
    "\n",
    "[jonas.volle@ovgu.de](mailto:jonas.volle@ovgu.de)\n",
    "\n",
    "**Sprechstunde**: individuell nach vorheriger Anmeldung per [Mail](mailto:jonas.volle@ovgu.de)\n",
    "\n",
    "Samstag, 17.06.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9256fa",
   "metadata": {},
   "source": [
    "**Quelle:** Ich orientiere mich für diese Sitzung am Kapitel 6 aus dem Buch:  \n",
    "\n",
    "McLevey, John. 2021. Doing Computational Social Science: A Practical Introduction. 1st ed. Thousand Oaks: SAGE Publications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278555f",
   "metadata": {},
   "source": [
    "# Tag 2: Datenmanagement mit Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6877dff4",
   "metadata": {},
   "source": [
    "## Inhalt\n",
    "\n",
    "- Datenstruktur\n",
    "- Import und Export verschiedener Dateiformate (csv, excel, etc.)\n",
    "- pandas DataFrame\n",
    "- Spalten (columns) auswählen\n",
    "- Zeilen (rows) filtern\n",
    "- Aggregierung und Gruppierung\n",
    "- Fehlende Daten\n",
    "- Merging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c456bf",
   "metadata": {},
   "source": [
    "Nun verwenden wir Python nicht mehr als allgemeine Programmiersprache, sondern zur Verarbeitung von Daten mit Hilfe spezieller Datenverwaltungs- und -analysepakete. Wir werden uns in erster Linie auf ein Paket namens *Pandas* stützen. Pandas wurde von Wes McKinney für die Analyse von Paneldaten entwickelt (daher der Name). Es verfügt über spezielle Datenstrukturen, Funktionen und Methoden, mit denen Sie die meisten Datenverarbeitungsvorgänge für strukturierte quantitative Daten erledigen können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d710e0",
   "metadata": {},
   "source": [
    "Pandas Dokumentation: https://pandas.pydata.org/docs/reference/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344a91c",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1fdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ac41756",
   "metadata": {},
   "source": [
    "## Datenimport mit pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9820909",
   "metadata": {},
   "source": [
    "Das Pandas-Paket macht es einfach, Daten aus einer externen Datei direkt in ein Dataframe-Objekt zu laden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dbb374",
   "metadata": {},
   "source": [
    "| Datentyp | Reader | Writer |\n",
    "|----------|----------|----------|\n",
    "| CSV    | `read_csv()`   | `to_csv()`   |\n",
    "| JSON    | `read_json()`   | `to_json()`   |\n",
    "| Stata   | `read_stata()`   | `to_stata()`   |\n",
    "| SAS   | `read_sas()`   | NA   |\n",
    "| SPSS   | `read_spss()`   | NA   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f714e",
   "metadata": {},
   "source": [
    "In diesem Kapitel werden Daten aus dem VDEM-Datensatz (Varieties of Democracy) verwendet. VDEM ist ein laufendes Forschungsprojekt zur Messung des Niveaus der Demokratie in Regierungen auf der ganzen Welt, und es werden laufend aktualisierte Versionen des Datensatzes veröffentlicht. Die Forschung wird von einem Team aus mehr als 50 Sozialwissenschaftlern geleitet, die die Sammlung und Analyse von Experteneinschätzungen von mehr als 3200 Historikern und Länderexperten koordinieren. Auf der Grundlage dieser Einschätzungen hat das VDEM-Projekt eine bemerkenswert komplexe Reihe von Indikatoren entwickelt, die sich an fünf übergeordneten Facetten der Demokratie orientieren: Wahldemokratie, liberale Demokratie, partizipative Demokratie, deliberative Demokratie und egalitäre Demokratie. Der Datensatz reicht bis ins Jahr 1789 zurück und gilt als Goldstandard für quantitative Daten über globale demokratische Entwicklungen.  \n",
    "\n",
    "Das Codebuch finden Sie hier: https://v-dem.net/documents/24/codebook_v13.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c89941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac048e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ab02d9d",
   "metadata": {},
   "source": [
    "Wie viele Zeilen und Spalten? Das geht mit der `.shape` Methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354dafa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09ece0e8",
   "metadata": {},
   "source": [
    "Welche Variablen benötigen wir? Wir wählen Spalten in einem DataFrame aus, indem wir den DataFrame aufrufen gefolt mit einer Liste in eckigen Klammern, die die Namen der Spalten enthält."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b127cd5",
   "metadata": {},
   "source": [
    "In diesem Fall möchten wir die folgenden Variablen behalten: \n",
    "\n",
    "1. den Ländernamen \n",
    "2. die Länder-ID \n",
    "3. die geografische Region \n",
    "4. Die Länder-ID \n",
    "3. die geographische Region \n",
    "4. Das Jahr 5. Der Polyarchie-Index \n",
    "6. Der Index der liberalen Demokratie\n",
    "7. Der Index der partizipativen Demokratie \n",
    "8. Der Index der deliberativen Demokratie \n",
    "9. Der Index der egalitären Demokratie \n",
    "10. Ob die Privatsphäre der Internetnutzer und ihre Daten rechtlich geschützt sind \n",
    "11. Wie polarisiert das Land in politischen Fragen ist \n",
    "12. Ausmaß der politischen Gewalt \n",
    "13. Ob das Land eine Demokratie ist oder nicht \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_vars = ['country_name', 'country_text_id', 'e_regiongeo', \n",
    "               'year', 'v2x_polyarchy', 'v2x_libdem', 'v2x_partipdem', \n",
    "               'v2x_delibdem', 'v2x_egaldem', 'v2smprivex', 'v2smpolsoc', \n",
    "               'v2caviol', 'e_boix_regime']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43e9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e3e2773",
   "metadata": {},
   "source": [
    "Wir können die Namen der Spalten (columns) mithilfe des Attributs `.columns` für den DataFrame ausdrucken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b2691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e171ef4",
   "metadata": {},
   "source": [
    "### Was ist im DataFrame?\n",
    "\n",
    "Mit der Methode `.info()` können wir die Gesamtzahl der Beobachtungen, die Gesamtzahl der Spalten, die Namen der Spalten, die Anzahl der nicht fehlenden Beobachtungen für jede Variable, den Datentyp für jede Variable, die Anzahl der Variablen, die Daten jedes Typs enthalten (z. B. Ganzzahlen und Fließkommazahlen), und die Gesamtmenge des vom DataFrame verwendeten Speichers anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd41756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e3d78eb",
   "metadata": {},
   "source": [
    "Die Datentypen in diesem Datenrahmen sind float64 (Zahlen mit Nachkommastellen), int64 (Ganzzahlen) und object. In Pandas bezieht sich object auf Spalten, die Strings oder gemischte Typen wie Strings und Integers enthalten (object umfasst auch viele andere Dinge: es ist eine Sammelkategorie). Pandas kann auch mit Booleans (Wahr oder Falsch), kategorischen Variablen und einigen speziellen Datetime-Objekten arbeiten. Erinnern Sie sich daran, wie wir die Spalten für unser Dataset ausgewählt haben. Im folgenden Code verwende ich dieselbe Idee, um nur einige wenige Variablen anzuzeigen. Wir werden dies später in diesem Kapitel noch etwas genauer erklären."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abec6ef",
   "metadata": {},
   "source": [
    "Wir können auch die Methode `.describe()` verwenden, um zusammenfassende Informationen über die quantitativen Variablen in unserem Datensatz zu erhalten, einschließlich der Anzahl der nicht fehlenden Informationen, des Mittelwerts und der Standardabweichung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc3d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cb1bcc8",
   "metadata": {},
   "source": [
    "### Heads, tails, and samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd86d06f",
   "metadata": {},
   "source": [
    "Wir können auch den \"Kopf\" oder das \"Ende\" unseres Datenrahmens mit den Methoden `.head() ` und `.tail()` untersuchen, die standardmäßig die ersten oder letzten fünf Zeilen in einem DataFrame verwenden, es sei denn, Sie geben eine andere Zahl als Argument an, wie z. B. `.head(10)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ac46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265deb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d443721a",
   "metadata": {},
   "source": [
    "Wenn Sie eine Zufallsstichprobe von Zeilen bevorzugen, können Sie die Methode `.sample()` verwenden, bei der Sie die Anzahl der Zeilen angeben müssen, die Sie abfragen möchten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a9ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c7fe471",
   "metadata": {},
   "source": [
    "### Zeilen filtern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f5505",
   "metadata": {},
   "source": [
    "Bei der Ausführung der Methode `.describe()` haben Sie vielleicht bemerkt, dass der Bereich für die Jahresvariable 1789-2019 ist. Angenommen, wir haben einen guten Grund, uns auf die Jahre von 1900 bis 2019 zu konzentrieren. Dann müssen wir die Daten filtern, um nur die Zeilen zu erhalten, die unseren Anforderungen entsprechen. Es gibt mehrere Möglichkeiten, Zeilen zu filtern, einschließlich Slices (z. B. alle Beobachtungen zwischen Index i und Index j) oder nach einer expliziten Bedingung, wie z. B. \"Zeilen, in denen das Jahr >= 1900\". Beachten Sie, dass, wenn wir einen DataFrame filtern oder zerschneiden, das neue Objekt nur eine Ansicht des Originals ist und sich immer noch auf die gleichen Daten bezieht. Pandas warnt uns, wenn wir versuchen, das gefilterte Objekt zu verändern, so dass es in den meisten Fällen einfacher ist, eine neue Kopie zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1924389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62e8416b",
   "metadata": {},
   "source": [
    "Wir könnten dies auch mit der Methode `.query()` tun, die einen booleschen Ausdruck als string annimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83785332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb7be409",
   "metadata": {},
   "source": [
    "### Schreiben von Dateien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd69f70",
   "metadata": {},
   "source": [
    "So wie wir unsere ursprüngliche CSV-Datei mit der Funktion `read_csv()` in Pandas eingelesen habe, können wir diesen neuen Dataframe mit der Methode `to_csv()` auch wieder schreiben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e7a0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b910716c",
   "metadata": {},
   "source": [
    "## Pandas Datenstruktur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1315e4",
   "metadata": {},
   "source": [
    "### The series\n",
    "\n",
    "Jede Spalte in einem dataframe ist ein Objekt namens Series. Eine Series ist ein eindimensionales Objekt (z. B. ein Zahlenvektor) mit einem Index, der selbst ein Vektor oder ein Array von Bezeichnungen ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7515b8c",
   "metadata": {},
   "source": [
    "Zum Beispiel ist die Spalte *v2x_delibdem* in fsdf eine Series, die Floats und die Indexbezeichnung für jede Beobachtung enthält. Wenn ich eine Stichprobe von 15 Beobachtungen ausdrucke, erhalte ich einen numerischen Index für jede Beobachtung auf der linken Seite und den tatsächlichen Wert auf der rechten Seite. Die Indexwerte sind in der Series selbst geordnet, aber hier sind sie nicht in der richtigen Reihenfolge, weil wir eine Zufallsstichprobe gezogen haben. Da dies nur zu Demonstrationszwecken dient, habe ich einen random_state-Wert eingefügt, um sicherzustellen, dass Sie die gleiche Stichprobe erhalten wie ich, wenn Sie diesen Block erneut ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2632ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961aa795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae3aa805",
   "metadata": {},
   "source": [
    "In den meisten Fällen ist der Standardindex für eine Series oder einen DataFrame ein unveränderlicher Vektor aus ganzen Zahlen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1e7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd0f4a92",
   "metadata": {},
   "source": [
    "Wir können einen Index leicht so ändern, dass er stattdessen aus einem anderen Vektortyp besteht, z. B. einem string. Überraschenderweise müssen Indexwerte nicht eindeutig sein. Dies ermöglicht einige leistungsfähige Techniken, aber die meiste Zeit sollten Sie vermeiden, Indizes manuell zu ändern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f9ac05",
   "metadata": {},
   "source": [
    "### Zugriff auf eine bestimmte Zeile über ihren Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0ce80",
   "metadata": {},
   "source": [
    "Wir können den Index verwenden, um bestimmte Zeilen aus einem dataframe oder bestimmte Werte aus einer series abzurufen, ganz so, als ob wir ein Element aus einer Liste, einem Tupel oder einem Array auswählen würden. Am einfachsten geht das, indem man den Indexwert (z. B. 202) an `.loc[]` übergibt. Wie Sie unten sehen können, ist das Ergebnis der beobachtungsspezifische Wert für jede Variable im dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330624f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517f3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a00e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a156428b",
   "metadata": {},
   "source": [
    "Beachten Sie, dass sich `.loc` nicht auf die 202. Zeile des dataframe bezieht. Wenn Sie sich den obigen `.index`-Befehl genau angesehen haben, ist Ihnen vielleicht aufgefallen, dass der dataframe nur 18.787 Zeilen enthält, aber `.loc` immer noch Zeile 20.000 zurückgeben kann - der Index hat sich nicht geändert, als Sie eine Reihe von Zeilen aus dem dataframe entfernt haben. Stellen Sie sich `.loc` als Zugriff auf ein Wörterbuch der Indexwerte vor - es gibt sogar einen KeyError, wenn Sie nach einem Element fragen, das nicht existiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331c529",
   "metadata": {},
   "source": [
    "Wenn wir stattdessen auf die n-te Zeile eines dataframe zugreifen wollen, können wir `.iloc[n]` verwenden. Stellen Sie sich den Index als eine Liste vor, und Sie beziehen sich auf ein Element dieser Liste durch seinen Listenindex. Verwenden wir `.iloc`, um das letzte Element im dataframe auszuwählen. Beachten Sie, dass die Indexposition für das letzte Element 18.786 sein wird, obwohl die Länge des dataframe 18.787 beträgt, da Python-Datenstrukturen fast immer mit einem Null-Index versehen sind. Hier sehen Sie den Index der Zeile, der früher die Zeilennummer war, als Name am unteren Rand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1595b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65def9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86874877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e68a8d4",
   "metadata": {},
   "source": [
    "Wenn es keinen Grund gibt, die ursprüngliche Indizierung des ungefilterten dataframe beizubehalten, ist es in der Regel eine gute Idee, den Index zurückzusetzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143301fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "297efa98",
   "metadata": {},
   "source": [
    "Danach werden `.loc` und `.iloc` ziemlich austauschbar, mit ein paar Ausnahmen: `.loc` hat wörterbuchähnliche Fähigkeiten, während `.iloc` eher listenähnlich ist. Schauen wir uns nun den dataframe genauer an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc790e",
   "metadata": {},
   "source": [
    "### Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51334ebe",
   "metadata": {},
   "source": [
    "Dataframes in Pandas sind eigentlich nur Sammlungen von Series, die an denselben Indexwerten ausgerichtet sind. Mit anderen Worten: Die Serien, mit denen wir zuvor gearbeitet haben, haben ihre eigenen Indizes, wenn wir mit ihnen als eigenständige Serien arbeiten, aber im fsdf dataframe teilen sie sich einen Index.  \n",
    "Wie Sie bereits gesehen haben, sind dataframes mit Variablen in den Spalten und Beobachtungen in den Zeilen organisiert, und Sie können eine einzelne series aus einem dataframe mit eckigen Klammern holen - lassen Sie uns das jetzt mit dem fsdf dataframe tun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3215176f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8354552",
   "metadata": {},
   "source": [
    "Beachten Sie, dass wir auch die Punktnotation verwenden können, um Spalten auszuwählen. `fsdf.v2x_delibdem` ist funktional gleichwertig mit `fsdf['v2x_delibdem']` und kann austauschbar verwendet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b0bae",
   "metadata": {},
   "source": [
    "Wir sind nicht darauf beschränkt, Spalten auszuwählen, die bereits in unserem Datensatz vorhanden sind. Sie können auch neue Spalten erstellen und hinzufügen. Sie können beispielsweise eine neue Spalte mit der Bezeichnung \"21. Jahrhundert\" erstellen und einen booleschen Wert zuweisen, der darauf basiert, ob die Beobachtung in den 2000er Jahren liegt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb9b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48635269",
   "metadata": {},
   "source": [
    "Manchmal handelt es sich bei den neu erstellten Spalten um Umwandlungen einer bereits im dataframe vorhandenen series. Sie können beispielsweise eine neue Spalte \"missing_political_violence_data\" erstellen, die den Wert \"True\" annimmt, wenn die Serie \"v2caviol\" (Ausmaß der politischen Gewalt) leer ist, und andernfalls \"False\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59478ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f2571dc",
   "metadata": {},
   "source": [
    "Wie Sie bei der Ausführung von value_counts() sehen können, fehlen für 6042 Beobachtungen Daten zum Ausmaß der politischen Gewalt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7723523",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cfa29e",
   "metadata": {},
   "source": [
    "Es ist wichtig zu verstehen, wie mit fehlenden Daten umgegangen wird. Fehlende Daten kommen in realen Datensätzen häufig vor, und sie können aus mehreren Gründen fehlen! Im Allgemeinen verwendet Pandas den Wert np.nan, um fehlende Daten darzustellen. Der np.nan-Wert von NumPy ist ein Spezialfall einer Fließkommazahl, die einen nicht darstellbaren Wert darstellt. Diese Art von Werten werden NaNs (Not a Number) genannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204df3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2978126",
   "metadata": {},
   "source": [
    "np.nan kann nicht in Gleichheitstests verwendet werden, da jeder Vergleich mit einem np.nan-Wert als Falsch ausgewertet wird. Dies schließt den Vergleich von np.nan mit sich selbst ein.  \n",
    "\n",
    "np.nan-Werte werden nicht zu False oder None ausgewertet. Dies kann es schwierig machen, fehlende Werte zu unterscheiden. Zu diesem Zweck können Sie die Funktion np.isnan() verwenden, die besonders im Kontrollfluss nützlich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bbc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.nan is None: \n",
    "    print('NaN is None') \n",
    "if np.nan: \n",
    "    print('NaN evaluates to True in control flow') \n",
    "if np.isnan(np.nan): \n",
    "    print('NaN is considered a NaN value in NumPy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ce879",
   "metadata": {},
   "source": [
    "Außerdem werden np.nan-Werte im Allgemeinen von Pandas-Funktionen ausgeschlossen, die Berechnungen über dataframes, Zeilen oder Spalten durchführen. In der Dokumentation wird zum Beispiel oft angegeben, dass eine Berechnung über alle Werte durchgeführt wird, wobei NaN- oder NULL-Werte ausgeschlossen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cf5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e65a64c1",
   "metadata": {},
   "source": [
    "Die Gesamtzahl der Elemente in der Spalte v2caviol (politische Gewalt) ist viel höher als die von der Funktion `count()` erhaltene Anzahl. Wenn das, was wir oben gelernt haben, richtig ist, sollte dieser Unterschied berücksichtigt werden, wenn wir herausfinden, wie viele Elemente in dieser Spalte NaNs sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535834ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e90d2070",
   "metadata": {},
   "source": [
    "Wie Sie wahrscheinlich wissen, kann die Methode `.isna()`, die der Methode `np.isnan()` ähnelt, aber zusätzliche Fälle abdeckt, beim Transformieren und Filtern von Daten sehr nützlich sein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4917664",
   "metadata": {},
   "source": [
    "### Aggregieren und Gruppieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ca519",
   "metadata": {},
   "source": [
    "Datenanalyseprojekte beinhalten oft Aggregations- oder Gruppierungsoperationen. So kann es beispielsweise erforderlich sein, zusammenfassende Statistiken für Beobachtungen zu berechnen und zu vergleichen, die unterschiedliche Werte für eine kategoriale Variable annehmen. Es kann hilfreich sein, den Datensatz selbst aufzuschlüsseln und Operationen auf verschiedenen Teilmengen von Daten durchzuführen. Dazu verwenden wir die Methode `.groupby()`, die den dataframe auf der Grundlage der Werte einer bestimmten Variable in Gruppen unterteilt. Anschließend können wir Operationen mit den resultierenden Gruppen durchführen. Wir gruppieren unsere Länder in geografische Regionen, indem wir die Variable *e_regiongeo* verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff2443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85efb557",
   "metadata": {},
   "source": [
    "Der obige Code gibt ein gruppiertes Objekt zurück, mit dem wir arbeiten können. Nehmen wir an, wir wollen eine bestimmte Gruppe herausziehen, z. B. Südostasien, die in den Daten mit der numerischen ID 13 dargestellt wird. Ich weiß das, weil die entsprechenden Informationen im VDEM-Codebuch zu finden sind, das Sie bei Ihrer Arbeit mit den VDEM-Daten immer geöffnet halten sollten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738072c",
   "metadata": {},
   "source": [
    "Wir können die Methode get_group() verwenden, um eine Gruppe aus dem gruppierten Objekt zu ziehen. (Beachten Sie, dass der nachstehende Code .get_group() fsdf[fsdf['e_regiongeo'] == 13] entspricht)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce530d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62f7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455866e4",
   "metadata": {},
   "source": [
    "Bei den in south_east_asia gespeicherten Daten handelt es sich um alle Beobachtungen der südostasiatischen Länder in den VDEM-Daten, die nun in einem eigenen dataframe gespeichert sind. .get_group() ist eine weitere Möglichkeit, eine Teilmenge eines dataframes zu extrahieren (mit Hilfe eines groupby-Objekts), und ist besonders nützlich, wenn die Teilmenge der Daten, mit der Sie arbeiten möchten, nur Beobachtungen mit einem bestimmten Wert für eine kategoriale Variable in Ihren Daten sind. Wenn wir einen Datensatz auf diese Weise gruppieren, geschieht dies im Allgemeinen, weil wir etwas für eine Gruppe innerhalb des Datensatzes oder für mehrere Gruppen, die wir vergleichen möchten, berechnen möchten. Dazu geben wir das gruppierte Objekt, die Serie, für die wir eine Operation durchführen möchten, und schließlich die Operation, die wir durchführen möchten, an. Berechnen wir zum Beispiel den Median des Polyarchie-Scores für Länder in jeder der Regionen im Datensatz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3630d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95a16b88",
   "metadata": {},
   "source": [
    "Es wäre nützlicher, den Namen der Region zu sehen als ihre numerische Bezeichnung. Wir können dies erreichen, indem wir ein Wörterbuch erstellen, das die numerischen IDs auf den Regionsnamen abbildet, und dann die Methode .map() verwenden, um Pandas mitzuteilen, wo es die Werte nachschlagen soll, die es benötigt, um eine neue Spalte mit den Ländernamen zu erstellen. Zuerst das Wörterbuch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = { 1:'Western Europe', \n",
    "           2:'Northern Europe', \n",
    "           3:'Southern Europe', \n",
    "           4:'Eastern Europe', \n",
    "           5:'Northern Africa',\n",
    "           6:'Western Africa', \n",
    "           7:'Middle Africa', \n",
    "           8:'Eastern Africa', \n",
    "           9:'Southern Africa', \n",
    "           10:'Western Asia', \n",
    "           11:'Central Asia', \n",
    "           12:'East Asia', \n",
    "           13:'South-East Asia', \n",
    "           14:'South Asia', \n",
    "           15:'Oceania', # (including Australia and the Pacific) \n",
    "           16:'North America', \n",
    "           17:'Central America', \n",
    "           18:'South America', \n",
    "           19:'Caribbean' # (including Belize Cuba Haiti Dominican Republic) \n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed6410",
   "metadata": {},
   "source": [
    "Nun können wir dieses Wörterbuch an die Methode `.map()` übergeben, die auf die Serie `fsdf['e_regiongeo']` angewendet wird, und so eine neue Serie namens `fsdf['Region']` erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b013830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7332d6d5",
   "metadata": {},
   "source": [
    "Es ist auch möglich, nach mehreren Variablen zu gruppieren, z. B. nach geografischer Region und Jahr, und dann eine Operation an diesen etwas feineren Gruppen durchzuführen. Auf diese Weise ergeben sich 2211 Gruppen, so dass wir eine Zufallsstichprobe von 10 Gruppen ansehen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71783d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "756f38b2",
   "metadata": {},
   "source": [
    "Für das gruppierte Objekt selbst können andere Operationen durchgeführt werden, z. B. die Berechnung der Anzahl der Beobachtungen in jeder Gruppe (entspricht value_counts()):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51268d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c346b9",
   "metadata": {},
   "source": [
    "Schließlich können wir mit der Methode `agg()` mehrere Operationen auf ein gruppiertes Objekt anwenden. Die `agg()`-Methode wendet eine oder mehrere Aggregatfunktionen auf ein gruppiertes Objekt an und gibt die Ergebnisse der einzelnen Funktionen zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c48e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4eb6a63",
   "metadata": {},
   "source": [
    "Wir können sogar unsere eigene Funktion definieren, die agg() verwenden soll! Wenn wir bereit sind, ein Wörterbuch zu übergeben, können wir mit .agg() auch verschiedene Funktionen auf mehrere Variablen gleichzeitig anwenden! Anstatt eine Liste pro Funktion zu übergeben, können Sie ein Wörterbuch verwenden, in dem die Spaltennamen die Schlüssel und die Funktionen die Werte sind (Sie können auch eine Liste von Funktionen übergeben), um eine wirklich komplexe Aggregation in einer einzigen Codezeile durchzuführen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3adc51",
   "metadata": {},
   "source": [
    "## Arbeiten mit Zeitreihendaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9c785",
   "metadata": {},
   "source": [
    "Viele reale Datensätze enthalten eine zeitliche Komponente. Dies gilt vor allem dann, wenn Sie mit Daten aus dem Internet arbeiten, die möglicherweise genaue Zeitangaben enthalten, z. B. den Zeitpunkt, zu dem eine E-Mail gesendet oder eine Nachricht veröffentlicht wurde. Strings werden oft verwendet, um Daten und Zeiten zu speichern, aber das ist nicht ideal. Es ist schwierig, Datumsangaben zu sortieren, wenn sie in Strings mit seltsamen Formaten gespeichert sind, z. B.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8664e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Monday Mar 2, 1999\" > \"Friday Feb 21, 2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b82e9",
   "metadata": {},
   "source": [
    "Das Extrahieren von Merkmalen wie Tag, Monat oder Zeitzone aus Strings kann zeitaufwändig und fehleranfällig sein. Aus diesem Grund haben Pandas und Python spezielle Typen für Datums-/Zeitobjekte implementiert, die Timestamp und Datetime heißen.  \n",
    "\n",
    "Die VDEM-Daten enthalten eine enorme Menge an zeitlichen Daten, allerdings alle auf Jahresebene. Wechseln wir nun zu einem anderen Datensatz, der feinere zeitliche Daten enthält und eher Daten aus dem Internet ähnelt. In diesem Fall werden wir einige Daten über russische Informationsoperationen zur amerikanischen Präsidentschaftswahl 2016 verwenden. Sie können ein wenig über diese Daten im FiveThirtyEight-Blogpost \"Why We're Sharing 3 Million Russian Troll Tweets\" lesen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c512e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d6d03f9",
   "metadata": {},
   "source": [
    "Wie Sie sehen können, haben wir zwei Datentypen in unserem dataframe: object und int64. Denken Sie daran, dass Pandas object verwendet, um auf Spalten zu verweisen, die Strings oder gemischte Typen wie Strings und Integer enthalten. In diesem Fall beziehen sie sich auf Strings.\n",
    "\n",
    "Eine weitere Anmerkung zu diesem Datensatz: Jede Zeile ist ein Tweet von einem bestimmten Konto, aber einige der Variablen beschreiben Attribute der tweetenden Konten, nicht des Tweets selbst. Die Variable Follower beschreibt beispielsweise die Anzahl der Follower, die das Konto zum Zeitpunkt des Tweets hatte. Dies ist sinnvoll, da Tweets keine Follower haben, Konten aber schon. Dies müssen wir bei der Arbeit mit diesem Datensatz im Auge behalten.   \n",
    "\n",
    "Mit der Funktion to_datetime können wir Datumsstrings aus einer Spalte oder Series in Zeitstempel umwandeln. Das werden wir hier tun, indem wir die neuen datetime-Objekte neuen Variablen zuweisen. Beachten Sie, dass die Ausführung dieses Codes etwas Zeit in Anspruch nimmt, wenn er auf allen 3 Millionen Tweets ausgeführt wird (wenn Ihr Computer nicht besonders leistungsfähig ist, sollten Sie zunächst die Methode .sample() verwenden, um die Größe des dataframe durch Ziehen einer Zufallsstichprobe von Beobachtungen zu verringern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97e880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5f038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b6c0afa",
   "metadata": {},
   "source": [
    "Die Felder des Datetime-Objekts lauten der Reihe nach wie folgt: Jahr-Monat-Tag Stunde:Minute: Sekunde:Mikrosekunde. Zum Abrufen einer ganzen Zahl, die dem Monat entspricht, in dem der Tweet veröffentlicht wurde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f816495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5cf7cfc",
   "metadata": {},
   "source": [
    "Wenn unsere Datums- und Zeitvariablen als datetime-Objekte gespeichert werden, können wir auf viele zeitspezifische Attribute mit der Punktnotation zugreifen. Die Pandas-Dokumentation enthält viele Beispiele für die Arten von zeitlichen Einheiten und andere Funktionen. Wir können unseren dataframe auch auf der Grundlage von publish_date sortieren, da Pandas weiß, dass es mit datetime-Objekten arbeitet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6631e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d1d3425",
   "metadata": {},
   "source": [
    "Wir können auch datetime-Spalten hinzufügen und subtrahieren, um neue Spalten zu erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b562e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "366350f3",
   "metadata": {},
   "source": [
    "Erstellen wir neue Variablen für das Jahr, den Monat und den Tag, an dem die einzelnen Tweets erstellt wurden. Dazu können wir die Attribute \"Jahr\", \"Monat\" und \"Tag\" des datetime-Objekts verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60c65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ae928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b4bb459",
   "metadata": {},
   "source": [
    "Pandas bietet spezielle Werkzeuge für die Gruppierung von Daten in verschiedene Zeitsegmente. Dies beinhaltet die Konvertierung einer Zeitserie von einer Ebene in eine andere (z. B. von Tagen in Wochen) und wird als Resampling bezeichnet. Im Rahmen des Resamplings aggregiert das Upsampling Daten/Zeiten und das Downsampling disaggregiert Daten/Zeiten. Nehmen wir ein Upsampling unserer Daten vor, um die Anzahl der Tweets pro Tag darzustellen.  \n",
    "\n",
    "Als Erstes verwenden wir das datetime-Objekt dt_publish_date als Index. Auf diese Weise können wir die Beobachtungen leicht nach dem Datum der Wiederholungsstichprobe gruppieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a7f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a411c3",
   "metadata": {},
   "source": [
    "Wir können nun die Methode .resample() mit dem Argument D verwenden, um anzugeben, dass wir nach Tagen gruppieren wollen. Tabelle 6.2 enthält einige weitere Optionen, die Sie bei der erneuten Stichprobenziehung von Daten verwenden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B         business day frequency\n",
    "# C         custom business day frequency (experimental)\n",
    "# D         calendar day frequency\n",
    "# W         weekly frequency\n",
    "# M         month end frequency\n",
    "# SM        semi-month end frequency (15th and end of month)\n",
    "# BM        business month end frequency\n",
    "# CBM       custom business month end frequency\n",
    "# MS        month start frequency\n",
    "# SMS       semi-month start frequency (1st and 15th)\n",
    "# BMS       business month start frequency\n",
    "# CBMS      custom business month start frequency\n",
    "# Q         quarter end frequency\n",
    "# BQ        business quarter endfrequency\n",
    "# QS        quarter start frequency\n",
    "# BQS       business quarter start frequency\n",
    "# A         year end frequency\n",
    "# BA, BY    business year end frequency\n",
    "# AS, YS    year start frequency\n",
    "# BAS, BYS  business year start frequency\n",
    "# BH        business hour frequency\n",
    "# H         hourly frequency\n",
    "# T, min    minutely frequency\n",
    "# S         secondly frequency\n",
    "# L, ms     milliseconds\n",
    "# U, us     microseconds\n",
    "# N         nanoseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ed56ce",
   "metadata": {},
   "source": [
    "We will also use the .size() method to determine the number of tweets that were produced each day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad3b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb425508",
   "metadata": {},
   "source": [
    "An dieser Stelle werden wir die Ergebnisse unserer Arbeit mit einem Liniendiagramm visualisieren. Dazu verwenden wir die Pakete Seaborn und Matplotlib, die wir im nächsten Kapitel besprechen werden. Konzentrieren Sie sich erst einmal auf die Visualisierung und ignorieren Sie den Code. Die folgenden Codeblöcke erzeugen die Abbildungen 6.1 und 6.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ab58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sns.lineplot(data=grouped_cal_day, color='#32363A') \n",
    "sns.despine() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93af6b",
   "metadata": {},
   "source": [
    "Die Darstellung ist viel übersichtlicher, wenn wir auf der Ebene der Wochen statt der Tage zählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44478d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=weekly, color='#32363A') \n",
    "ax.set_xlabel('\\nWeekly observations') \n",
    "ax.set_ylabel('Number of tweets\\n') \n",
    "sns.despine() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b33641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ad55fc",
   "metadata": {},
   "source": [
    "## Kombinierung von DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09d8f8",
   "metadata": {},
   "source": [
    "Das Kombinieren von dataframes ist eine sehr häufige Aufgabe. Auch wenn es nicht offensichtlich erscheint, ist das Kombinieren von Datensätzen eine der wertvollsten Fähigkeiten, die man in der rechnergestützten Sozialwissenschaft haben kann. Im Folgenden werden einige der gebräuchlichsten Ansätze betrachtet, nämlich die Verkettung und Zusammenführung, und es wird kurz eine fortgeschrittenere Reihe von Methoden beschrieben, die gemeinhin als Datensatzverknüpfung bezeichnet werden.  \n",
    "\n",
    "Die Verkettung eines dataframes ist konzeptionell recht einfach - stellen Sie sich vor, Sie hängen die Zeilen oder Spalten eines dataframes unter oder rechts von der letzten Zeile oder Spalte eines anderen dataframes an. Damit dies sinnvoll ist, sollten die beiden dataframes mindestens eine Zeile oder Spalte gemeinsam haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee737f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9447a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c5f66fd",
   "metadata": {},
   "source": [
    "Standardmäßig führt pd.concat() eine zeilenweise Verknüpfung durch, die als Achse=0 bezeichnet wird. Diese Vorgabe kann durch die Angabe von Achse=1 außer Kraft gesetzt werden, wodurch eine spaltenweise Verknüpfung erfolgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42f695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9040f408",
   "metadata": {},
   "source": [
    "Wenn wir die beiden dataframes verketten, bleibt die Anzahl der Spalten gleich, aber die Anzahl der Zeilen erhöht sich, da die Zeilen in beiden ursprünglichen dataframes berücksichtigt werden. Normalerweise würde diese Art der Verkettung zu einer unterschiedlichen Anzahl von Spalten führen, aber in diesem Fall hatten die beiden Dataframes, die wir zusammengefügt haben, genau die gleichen Spalten (was sinnvoll ist, da sie beide aus demselben übergeordneten Dataframe extrahiert wurden)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dff2ed",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c870e4",
   "metadata": {},
   "source": [
    "Eine andere Möglichkeit, Datensätze zu kombinieren, ist ihre Zusammenführung. Wenn Sie einen dataframe erstellen möchten, der Spalten aus mehreren Datensätzen enthält, aber in den Zeilen nach einer bestimmten Spalte (oder einem Satz von Spalten) ausgerichtet ist, sollten Sie die Funktion merge() verwenden. Um dies zu veranschaulichen, werden wir mit Daten aus zwei verschiedenen Quellen arbeiten. Die erste Quelle sind die VDEM-Daten, die wir im ersten Teil dieses Kapitels verwendet haben (fsdf). Die zweite ist ein Datensatz von Freedom House über den Grad der Internetfreiheit in 65 Ländern. Weitere Informationen finden Sie unter https://freedomhouse.org/countries/freedom-net/scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf008504",
   "metadata": {},
   "source": [
    "Um diese dataframes zusammenzuführen, müssen wir eine Spalte finden, mit der wir die Zeilen des einen dataframes mit den Zeilen des anderen abgleichen können. Die Spalten müssen nicht den gleichen Namen haben, sondern nur Werte, die einander zugeordnet werden können. Die von uns gewählten Spalten werden in unserer Zusammenführung als \"Schlüssel\" bezeichnet. In unserem Fall sind dies die Spalten mit den Ländernamen aus jedem Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b34cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c9656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6616081",
   "metadata": {},
   "source": [
    "Wir verwenden die Funktion \"Zusammenführen\", um diese beiden dataframes mit \"country_name\" und \"Country\" zu kombinieren. Wir führen einen inner-join durch, was der Standard ist, wenn die Option nicht gesetzt ist, und behalten nur die Schlüssel (d. h. Länder), die in beiden dataframes erscheinen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f8725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb938849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025ed42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eab0ab80",
   "metadata": {},
   "source": [
    "Sie sollten fünf neue Spalten in dem zusammengeführten dataframe im Vergleich zu dem fsdf-Dataframe sehen. Beachten Sie, wie viele Zeilen jeder der beiden dataframes hat: viel weniger Zeilen als der ursprüngliche VDEM dataframe, aber viel mehr als der Freedom House dataframe. Wenn also in unserem Fall das Land einer Zeile in dem anderen Datensatz nicht vorkommt, wird diese Zeile nicht in den zusammengeführten dataframe aufgenommen.  \n",
    "\n",
    "Dies kann mit dem Parameter how angepasst werden. Es gibt fünf Möglichkeiten, dataframes in Pandas zusammenzuführen: left, right, outer, inner und cross. In der Dokumentation können Sie nachlesen, wie die anderen vier Methoden funktionieren.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
