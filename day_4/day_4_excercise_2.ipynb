{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a93d4c",
   "metadata": {},
   "source": [
    "# Tag 4 - Übung 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61279177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import re # regex\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from collections import Counter\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0853458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/guardian_articles_23_06_20-23_06_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43fa26",
   "metadata": {},
   "source": [
    "Welche Wörter werden in den ersten 100 Texten am häufigsten verwendet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546cc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste 10 Texte\n",
    "df_100 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all tweets with spaCy and extract all tokens\n",
    "\n",
    "\n",
    "# Count the occurrences of each token and create a vocabulary of unique tokens\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c35f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49962fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c887d29",
   "metadata": {},
   "source": [
    "Welche Bigrams kommen in den Texten vor? Welche Bigrams kommen am häufigsten vor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# gensim expect as input tokenized texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14abd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d4814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eddeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b05d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "658b8f4d",
   "metadata": {},
   "source": [
    "Welche Personen kommen in den ersten 100 Texten vor? Benutzen Sie dafür die NER tags von Spacy und verwenden Sie diesen Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a962f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste 10 Texte\n",
    "df_100 = df.head(100).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0eb7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1274bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model with NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define an array to store the people cited\n",
    "persons_cited = []\n",
    "\n",
    "# Loop over each text and analyze it with spaCy's NER\n",
    "for text in df_100.text:\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            # If the entity is a person, add it to the array \n",
    "            persons_cited.append(ent.text)\n",
    "\n",
    "citations_count = Counter(persons_cited)\n",
    "citations_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec519b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b8f1e01",
   "metadata": {},
   "source": [
    "Filtern Sie alle Verben (`VERB`) aus dem ersten 100 Text. Zählen Sie die Verben anschließend. Welche Verben kommen am häufigsten vor? Sie müssen das Script der NERs nur etwas abändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea79db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste 100 Texte\n",
    "df_100 = df.head(100).copy()\n",
    "\n",
    "# Load the pre-trained model with NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define an array to store the people cited\n",
    "words = []\n",
    "\n",
    "# Loop over each text and analyze it with spaCy's NER\n",
    "for text in df_100.text:\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        ################:\n",
    "            # If the token is a verb, add it to the array \n",
    "            words.append(token.text)\n",
    "\n",
    "words_count = Counter(words)\n",
    "words_count.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ffdf0",
   "metadata": {},
   "source": [
    "Implementieren Sie die Preprocessing Pipeline aus dem Script und erstellen Sie einen Corpus aus den Texten vom Guardian. (Wenn die Lemmatizierung auf Ihrem Rechner zu lange dauern sollte, verwenden Sie anstatt dessen das Stemmen) Erstellen Sie ein Dictionary und eine Document-Term-Matrix. Sichern Sie alles anschließend im pickle Format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4bc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3b599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec47cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba672bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065b2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940b0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee8f5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022666e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13eea96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207378e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3b632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be73ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47dbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0bde8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b8479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34e7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e787e062",
   "metadata": {},
   "source": [
    "Berechnen Sie ein Topic Model mit 10 Topics für die Texte und interpretieren Sie es mit `pyLDAvis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763e577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71d99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caeba4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
